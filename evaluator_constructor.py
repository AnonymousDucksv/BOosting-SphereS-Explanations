"""
Evaluator constructor
"""

"""
Imports
"""
import numpy as np
import pandas as pd
import copy
from sklearn.linear_model import RidgeClassifier
from sklearn.metrics.pairwise import cosine_similarity

class Evaluator:
    """
    Class that evaluates the perturbations created in terms of their explainability metrics
    Attributes:
        (1) name:               Dataset name, 
        (2) ord_scaler:         Ordinal feature scaler,
        (3) con_scaler:         Continuous feature scaler,
        (4) train_pd:           Training dataset dataframe,
        (5) processed_train_pd: Processed training dataset dataframe,
        (6) train_target:       Training dataset targets,
        (7) x_iterations:       Number of iterations for the robustness evaluation,
        (8) eval_columns:       Columns of the LEA evaluation dataframe
        (9) all_eval_df:        Dataframe containing the evaluation performance of each method for each instance of interest. 
    """
    def __init__(self,data_obj,
                 x_iterations) -> None:
                 
        self.name = data_obj.name
        self.ord_scaler, self.con_scaler = data_obj.ord_scaler, data_obj.con_scaler
        self.train_pd, self.processed_train_pd, self.train_target = data_obj.train_pd, data_obj.processed_train_pd, data_obj.train_target
        self.x_iterations = x_iterations
        self.eval_columns = ['ioi','local_method','perturbations','processed_pert',
                             'pert_weights','lin_model','global_model','true_expl_x','closest_x',
                             'processed_x1_x2','acccuracy','fidelity','robustness','feasibility','time']
        self.all_eval_df = pd.DataFrame(columns = self.eval_columns)

    def train_linear_model(self,perturbator_obj,regul=0.1,):
        """
        Method that trains a linear model based on the perturbator object data and attributes
        Input perturbator_obj: Perturbator object
        Input regul: Regularization parameter set up as 0.1 by default
        Output lin_model: Local linear model trained on the perturbations obtained
        """
        perturbations, perturbations_weights, perturbations_label = perturbator_obj.processed_perturbations, perturbator_obj.pert_weights, perturbator_obj.perturbations_label
        lin_model = RidgeClassifier(alpha=regul)
        lin_model.fit(perturbations,perturbations_label,sample_weight=perturbations_weights.reshape(perturbations_label.shape))
        return lin_model

    def coefficient_accuracy(self, lin_model, perturbator):
        """
        Method that calculates the feature coefficient accuracy between the linear and the global model
        Input lin_model: Local linear model trained on the perturbations obtained
        Input perturbator: Perturbator object
        Output coefficient_acc: The accuracy coefficient as measured by the cosine similarity between either ground truth or global linear model
        """
        linear_model_coef = lin_model.coef_
        if perturbator.ioi.true_expl_x is None:
            global_model_coef = perturbator.global_model.call_coefficients(perturbator.ioi,self.processed_train_pd,self.train_target)
        else:
            global_model_coef = perturbator.ioi.true_expl_x
        coefficient_acc = cosine_similarity(global_model_coef, linear_model_coef)
        return coefficient_acc[0][0]
    
    def fidelity(self, lin_model, perturbator_obj):
        """
        Method that calculates the fidelity of the local model w.r.t. the predicted labels
        Input lin_model: Local linear model trained on the perturbations obtained
        Input perturbator: Perturbator object
        Output fidelity_ratio: The fidelity ratio between the global or ground truth labels and the local linear labels
        """
        linear_prediction_label = lin_model.predict(perturbator_obj.processed_perturbations)
        verification_labels = linear_prediction_label == perturbator_obj.perturbations_label
        fidelity_ratio = np.sum(verification_labels)/len(linear_prediction_label)
        return fidelity_ratio

    def robustness(self, perturbator_obj):
        """
        Method that calculates the robustness of the perturbations generated by the perturbator object on the described iterations on x
        Input perturbator: Perturbator object
        Output mean_lin_coefficients_cv: Average of the absolute variation coefficient among different iterations of the local explainer algorithm
        """
        lin_coefficients_list = []
        for i in range(self.x_iterations):
            seed_random_sel = np.random.randint(1,10000,1)
            perturbator_i = copy.deepcopy(perturbator_obj)
            perturbator_i.perturbations, perturbator_i.processed_perturbations, perturbator_i.pert_weights, some_exec_time = perturbator_i.perturbation_function(perturbator_i.regul, seed_random_sel, True)
            perturbator_i.perturbations_label = perturbator_i.perturbation_target()
            lin_model_i = self.train_linear_model(perturbator_i)
            linear_model_coef = lin_model_i.coef_
            lin_coefficients_list.append(linear_model_coef)
        lin_coefficients_mean_feat = np.abs(np.mean(lin_coefficients_list,axis=0))
        lin_coefficients_std_feat = np.std(lin_coefficients_list,axis=0,ddof=1)
        lin_coefficients_mean_feat_denom = np.copy(lin_coefficients_mean_feat)
        lin_coefficients_mean_feat_denom[np.abs(lin_coefficients_mean_feat_denom) < 1] = 1
        lin_coefficients_cv = lin_coefficients_std_feat / lin_coefficients_mean_feat
        mean_lin_coefficients_cv = np.mean(lin_coefficients_cv)
        return mean_lin_coefficients_cv

    def feasibility(self, perturbator_obj):
        """
        Method that indicates whether cf is a feasible counterfactual with respect to x and the feature mutability
        Input perturbator: Perturbator object
        Output feasibility_ratio: The ratio of feasible instances w.r.t. the total number of instances generated in the neighborhood
        """
        toler = 0.000001
        if len(perturbator_obj.ordinal) > 0: 
            feat_step_ord = pd.Series(data=1/(self.ord_scaler.data_max_ - self.ord_scaler.data_min_),index=[i for i in perturbator_obj.features if i in perturbator_obj.ordinal])
        feasible_counter = 0
        for i in range(perturbator_obj.processed_perturbations.shape[0]):
            pert_i = perturbator_obj.processed_perturbations[i,:]
            feasibility = True
            for j in range(len(perturbator_obj.processed_features)):
                feat_j = perturbator_obj.processed_features[j]
                if feat_j in perturbator_obj.bin_enc_cols:
                    if not np.isclose(pert_i[j],[0,1],atol=toler).any():
                        feasibility = False
                        break
                elif feat_j in perturbator_obj.cat_enc_cols:
                    if not np.isclose(pert_i[j],[0,1],atol=toler).any():
                        same_cat_idx = perturbator_obj.idx_cat_cols_dict[feat_j[:-2]]
                        if not np.isclose(np.sum(pert_i[same_cat_idx]),1,atol=toler):
                            feasibility = False
                            break
                elif feat_j in perturbator_obj.ordinal:
                    possible_val = np.linspace(0,1,int(1/feat_step_ord[feat_j]+1),endpoint=True)
                    if not np.isclose(pert_i[j],possible_val,atol=toler).any():
                        feasibility = False
                        break
                else:
                    if pert_i[j] < 0-toler or pert_i[j] > 1+toler:
                        feasibility = False
                        break
            if feasibility:
                feasible_counter += 1
        feasibility_ratio = feasible_counter/len(perturbator_obj.perturbations)
        return feasibility_ratio
    
    def add_perturbator_eval(self, perturbator_obj):
        """
        Method that adds a perturbator performance metrics set to the evaluator
        Input perturbator: Perturbator object
        """
        trained_linear_model = self.train_linear_model(perturbator_obj)
        accuracy = self.coefficient_accuracy(trained_linear_model, perturbator_obj)
        fidelity_ratio = self.fidelity(trained_linear_model, perturbator_obj)
        feat_robustness = self.robustness(perturbator_obj)
        feasibility_ratio = self.feasibility(perturbator_obj)
        df_pert_performance = pd.DataFrame(data = [[perturbator_obj.ioi,perturbator_obj.type,perturbator_obj.perturbations,perturbator_obj.processed_perturbations,
                                                    perturbator_obj.pert_weights,trained_linear_model,perturbator_obj.global_model,perturbator_obj.ioi.true_expl_x,perturbator_obj.processed_closest_x,
                                                    perturbator_obj.processed_x1_x2,accuracy,fidelity_ratio,feat_robustness,feasibility_ratio,perturbator_obj.exec_time]],columns = self.eval_columns)
        self.all_eval_df = self.all_eval_df.append(df_pert_performance)

